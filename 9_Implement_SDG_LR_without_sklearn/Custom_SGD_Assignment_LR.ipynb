{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "\n",
    "X, y = make_classification(n_samples = 50000, n_features = 15, n_informative = 10, n_redundant = 5,\n",
    "                           n_classes = 2, weights = [0.7], class_sep = 0.7, random_state = 15)\n",
    "\n",
    "# make_classification is used to create custom dataset \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "# you need not standardize the data as it is already standardized\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0 = 0.0001, alpha = 0.0001, loss = 'log', random_state = 15,\n",
    "                             penalty = 'l2', tol = 1e-3, verbose = 2, learning_rate = 'constant')\n",
    "clf\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 10 epochs took 0.07 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X = X_train, y = y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term\n",
    "\n",
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "#you use zeros_like function to initialize zero,\n",
    "#https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html\n",
    "#initialize bias to zero\n",
    "    \n",
    "def initialize_weights(row_vector):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    \n",
    "    w = np.zeros_like(row_vector)\n",
    "    b = 0\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = X_train[0] \n",
    "\n",
    "# w,b = initialize_weights(row_vector)\n",
    "w,b = initialize_weights(dim)\n",
    "\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='red'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "\n",
    "def grader_weights(w,b):\n",
    "    assert((len(w) == len(dim)) and b == 0 and np.sum(w) == 0.0)\n",
    "    return True\n",
    "\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "# https://numpy.org/doc/stable/reference/generated/numpy.exp.html\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    \n",
    "    # compute sigmoid(z) and return\n",
    "    sigmoid_ = (1 / (1 + np.exp(-z)))\n",
    "    \n",
    "    return sigmoid_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='red'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    \n",
    "    val = sigmoid(z)\n",
    "    assert(val == 0.8807970779778823)\n",
    "    \n",
    "    return True\n",
    "\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "# https://numpy.org/doc/stable/reference/generated/numpy.log10.html\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "    \n",
    "    sum_ = 0\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        sum_ += y_true[i] * np.log10(y_pred[i]) + (1- y_true[i]) * (np.log10(1-y_pred[i]))\n",
    "        \n",
    "    loss = -1 * (1/len(y_true)) * sum_\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='red'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#round off the value to 8 values\n",
    "\n",
    "def grader_logloss(true, pred):\n",
    "    \n",
    "    loss = logloss(true,pred)\n",
    "    assert(np.round(loss,6) == 0.076449)\n",
    "    \n",
    "    return True\n",
    "\n",
    "true = np.array([1,1,0,1,0])\n",
    "pred = np.array([0.9,0.8,0.1,0.8,0.2])\n",
    "\n",
    "grader_logloss(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "# https://numpy.org/doc/stable/reference/generated/numpy.transpose.html\n",
    "\n",
    "def gradient_dw(x, y, w, b, alpha, N):\n",
    "    \n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "\n",
    "    dw = x * (y - sigmoid(np.dot(np.transpose(w),x) + b)) - (( alpha / N) * w)\n",
    "    \n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='red'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x, y, w, b, alpha, N):\n",
    "    \n",
    "    grad_dw = gradient_dw(x,y,w,b,alpha,N)\n",
    "    assert(np.round(np.sum(grad_dw),5) == 4.75684)\n",
    "    return True\n",
    "\n",
    "grad_x = np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y = 0\n",
    "grad_w = np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
    "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
    "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
    "\n",
    "grad_b = 0.5\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "\n",
    "grader_dw(grad_x, grad_y, grad_w, grad_b, alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    "def gradient_db(x, y, w, b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "        \n",
    "    db = y - (sigmoid(np.dot(np.transpose(w), x) + b))\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='red'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x, y, w, b):\n",
    "    \n",
    "    grad_db=gradient_db(x,y,w,b)\n",
    "    assert(np.round(grad_db,4) == -0.3714)\n",
    "    return True\n",
    "\n",
    "grad_x = np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "\n",
    "grad_y = 0.5\n",
    "grad_b = 0.1\n",
    "\n",
    "grad_w = np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
    "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
    "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
    "\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "\n",
    "grader_db(grad_x, grad_y, grad_w, grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function used to compute predicted_y given the dataset X\n",
    "\n",
    "def pred(w, b, X):\n",
    "    \n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        z = np.dot(w, X[i]) + b\n",
    "        predict.append(sigmoid(z))\n",
    "        \n",
    "    return np.array(predict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://youtu.be/Zc6RBeTrYjE?t=503 : SGD Assignment\n",
    "\n",
    "def pred(w,b, x):\n",
    "\n",
    "    N = len(x)\n",
    "    predict = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        z = np.dot(w,x[i]) + b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "            \n",
    "    return np.array(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, epochs, alpha, eta0, N):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    \n",
    "    w, b = initialize_weights(X_train[0])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i in range(N):\n",
    "            dw = gradient_dw(X_train[i], y_train[i], w, b, alpha, N)\n",
    "            db = gradient_db(X_train[i], y_train[i], w, b)\n",
    "            \n",
    "#             w = w - (eta0 * dw)\n",
    "#             b = b - (eta0 * db)\n",
    "\n",
    "# https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/\n",
    "            w = w + (eta0 * dw)\n",
    "            b = b + (eta0 * db)\n",
    "            \n",
    "        train_pred = pred(w, b, X_train)\n",
    "    \n",
    "        train_pred_loss = logloss(y_train, train_pred)\n",
    "        train_loss.append(train_pred_loss)\n",
    "        \n",
    "        test_pred = pred(w, b, X_test)\n",
    "            \n",
    "        test_pred_loss = logloss(y_test,test_pred)\n",
    "        test_loss.append(test_pred_loss)\n",
    "        \n",
    "    return w, b, train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [],
   "source": [
    "# https://youtu.be/Zc6RBeTrYjE : SGD Assignment\n",
    "\n",
    "# alpha = 0.001\n",
    "# eta0 = 0.001\n",
    "eta0 = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "epochs = 20\n",
    "\n",
    "w, b, train_loss, test_loss = train(X_train, y_train, X_test, y_test, epochs, alpha, eta0, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.29394713e-01  1.92911531e-01 -1.48319226e-01  3.38095811e-01\n",
      " -2.20731189e-01  5.69669865e-01 -4.45186056e-01 -9.00099226e-02\n",
      "  2.21598219e-01  1.73588003e-01  1.98538391e-01 -4.13172177e-04\n",
      " -8.11250040e-02  3.39070544e-01  2.29369069e-02]\n",
      "-0.8897519322788823\n"
     ]
    }
   ],
   "source": [
    "#print thr value of weights w and bias b\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0060278 ,  0.00743588,  0.00027113, -0.00334826, -0.01254449,\n",
       "          0.00950408,  0.00723877,  0.00407821,  0.01232502, -0.00725326,\n",
       "          0.00148649, -0.00463233, -0.00152131,  0.00054253,  0.0002697 ]]),\n",
       " array([-0.03661363]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "\n",
    "w - clf.coef_, b - clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "## <font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in order of 10^-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Grader function - 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The custom weights are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this grader function should return True\n",
    "#the difference between custom weights and clf.coef_ should be less than or equal to 0.05\n",
    "\n",
    "def differece_check_grader(w, b, coef, intercept):\n",
    "    \n",
    "    val_array = np.abs(np.array(w - coef))\n",
    "    assert(np.all(val_array <= 0.05))\n",
    "    \n",
    "    print('The custom weights are correct')\n",
    "    return True\n",
    "\n",
    "differece_check_grader(w, b, clf.coef_, clf.intercept_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot your train and test loss vs epochs </font>\n",
    "\n",
    "plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1O6GrRt7UeCJ",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epoch = np.arange(20) + 1\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.plot(epoch,train_loss , label='Train Log Loss')\n",
    "plt.plot(epoch,test_loss, label='Test Log Loss')\n",
    "plt.xticks(epoch)\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
