{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2ZRzYGsCSnt"
   },
   "source": [
    "\n",
    "### 1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>. You have to use data.csv file for this assignment\n",
    "### 2. Code the model to classify data like below image. You can use any number of units in your Dense layers.\n",
    "\n",
    "<img src='https://i.imgur.com/33ptOFy.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg22rD7sDPDu"
   },
   "source": [
    "# <font color='red'> <b>3. Writing Callbacks </b> </font>\n",
    "## You have to implement the following callbacks\n",
    "-  Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.Do not use tf.keras.metrics for calculating AUC and F1 score.\n",
    "\n",
    "- Save your model at every epoch if your validation accuracy is improved from previous epoch. \n",
    "\n",
    "- You have to decay learning based on below conditions \n",
    "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
    "               learning rate by 10%. \n",
    "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
    "        \n",
    "- If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n",
    "\n",
    "- You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
    "\n",
    "- Use tensorboard for every model and analyse your scalar plots and histograms. (you need to upload the screenshots and write the observations for each model for evaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./N_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZaRHRdEHDzOM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 16:19:30.742067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-05 16:19:30.742121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CSw5K9mrDzRq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data set : (20000, 3)\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/tutorials/load_data/csv\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "print(f'Shape of data set : {data.shape}')\n",
    "# pd.read_csv('data.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10000\n",
       "1.0    10000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how the data is balanced !\n",
    "\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train-test\n",
    "\n",
    "y_label = data.label\n",
    "x_values = data.drop(['label'], axis = 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_label, test_size = 0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color ='red'>Custom Callbacks</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roc_score(Callback):\n",
    "    \n",
    "    def __init__(self, train_x, test_x, train_y, test_y):\n",
    "        \n",
    "        self.x_tr = train_x\n",
    "        self.y_tr = train_y\n",
    "        self.x_te = test_x\n",
    "        self.y_te = test_y\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "\n",
    "        y_pred_tr = self.model.predict(self.x_tr)\n",
    "        y_pred_te = self.model.predict(self.x_te)\n",
    "            \n",
    "        roc_tr = roc_auc_score(self.y_tr, y_pred_tr)\n",
    "        roc_te = roc_auc_score(self.y_te, y_pred_te)\n",
    "        \n",
    "        print(f' ROC_test:{round(roc_te, 3)}')\n",
    "\n",
    "class f1_score_(Callback):\n",
    "    \n",
    "    def __init__(self, train_x, test_x, train_y, test_y):\n",
    "        \n",
    "        self.x_tr = train_x\n",
    "        self.y_tr = train_y\n",
    "        self.x_te = test_x\n",
    "        self.y_te = test_y\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "\n",
    "        y_pred_tr = (np.array(self.model.predict(self.x_tr))).round()\n",
    "        y_pred_te = (np.array(self.model.predict(self.x_te))).round()\n",
    "            \n",
    "        f1_tr = f1_score(self.y_tr, y_pred_tr, average = 'micro')\n",
    "        f1_te = f1_score(self.y_te, y_pred_te, average = 'micro')\n",
    "        \n",
    "        print(f' MicroF1_Test:{round(f1_te, 3)}')\n",
    "\n",
    "        \n",
    "class TerminateNaN(Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        \n",
    "        loss = logs.get('loss')\n",
    "        \n",
    "        if loss is not None:\n",
    "            \n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(F'Invalid loss and terminated at epoch {epoch}')\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "                \n",
    "roc_score = roc_score(x_train, x_test, y_train, y_test)\n",
    "\n",
    "f1_score_ = f1_score_(x_train, x_test, y_train, y_test)\n",
    "\n",
    "terminateNaN = TerminateNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/callbacks/model_checkpoint/\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "# https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 2, verbose = 1)\n",
    "\n",
    "filpath = 'me_model_save/epo_{epoch:02d}-accu_{val_accuracy:.4f}.hdf5'\n",
    "model_check_point = ModelCheckpoint(filpath, monitor = 'val_accuracy', patience = 1, verbose = 1)\n",
    "\n",
    "\n",
    "# factor: factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "# lr = 0.1, factor = 0.9.\n",
    "# Then, new_lr = 0.09 ==> 10% reduction\n",
    "\n",
    "epoch_1 = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.9, verbose = 1, patience = 1) # 10% reduction\n",
    "epoch_3 = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.95, verbose = 1, patience = 3) # 5% reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activ, initializer):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape = (2,), kernel_initializer = initializer, name = 'input_layer'))\n",
    "    model.add(Dense(32, activation = activ, kernel_initializer = initializer, name = 'dense1'))\n",
    "    model.add(Dense(32, activation = activ, kernel_initializer = initializer, name = 'dense2'))\n",
    "    model.add(Dense(32, activation = activ, kernel_initializer = initializer, name = 'dense3'))\n",
    "    model.add(Dense(32, activation = activ, kernel_initializer = initializer, name = 'dense4'))\n",
    "    model.add(Dense(32, activation = activ, kernel_initializer = initializer, name = 'dense5'))\n",
    "    model.add(Dense(1, activation = 'sigmoid', name = 'output_layer'))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCL3OGS0DsUa"
   },
   "source": [
    "<br>\n",
    "<b>Model-1</b>\n",
    "<pre>\n",
    "1. Use tanh as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use RandomUniform(0,1) as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 32)                96        \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense4 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense5 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,409\n",
      "Trainable params: 5,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 16:19:32.506025: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-05 16:19:32.506055: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-05 16:19:32.506072: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2022-03-05 16:19:32.506732: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "kernel_init = RandomUniform(0, 1)\n",
    "\n",
    "model = create_model('tanh', kernel_init)\n",
    "\n",
    "optimizer_ = optimizers.SGD(learning_rate = 0.001, momentum = 0.9, name = 'SGD')\n",
    "\n",
    "model.compile(optimizer = optimizer_, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "\n",
    "log_dir = 'N_logs/1_tanh_Random'\n",
    "tensorboard_ = TensorBoard(log_dir = log_dir, histogram_freq = 1, write_graph = True)\n",
    "\n",
    "CallBack_list = [roc_score, f1_score_, terminateNaN, early_stopping, model_check_point,\n",
    "                                                                     epoch_1, epoch_3, tensorboard_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/438 [..............................] - ETA: 3:33 - loss: 0.6914 - accuracy: 0.5312WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.\n",
      "425/438 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.4993 ROC_test:0.496\n",
      " MicroF1_Test:0.496\n",
      "\n",
      "Epoch 1: saving model to me_model_save/epo_01-accu_0.4960.hdf5\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6935 - accuracy: 0.4995 - val_loss: 0.6936 - val_accuracy: 0.4960 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "429/438 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.4927 ROC_test:0.496\n",
      " MicroF1_Test:0.496\n",
      "\n",
      "Epoch 2: saving model to me_model_save/epo_02-accu_0.4960.hdf5\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6939 - accuracy: 0.4918 - val_loss: 0.6933 - val_accuracy: 0.4960 - lr: 9.0000e-04\n",
      "Epoch 3/20\n",
      "414/438 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.4973 ROC_test:0.504\n",
      " MicroF1_Test:0.504\n",
      "\n",
      "Epoch 3: saving model to me_model_save/epo_03-accu_0.5040.hdf5\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6937 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5040 - lr: 9.0000e-04\n",
      "Epoch 4/20\n",
      "417/438 [===========================>..] - ETA: 0s - loss: 0.6939 - accuracy: 0.5017 ROC_test:0.504\n",
      " MicroF1_Test:0.504\n",
      "\n",
      "Epoch 4: saving model to me_model_save/epo_04-accu_0.5040.hdf5\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6939 - accuracy: 0.5019 - val_loss: 0.6934 - val_accuracy: 0.5040 - lr: 8.1000e-04\n",
      "Epoch 5/20\n",
      "431/438 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5081 ROC_test:0.504\n",
      " MicroF1_Test:0.494\n",
      "\n",
      "Epoch 5: saving model to me_model_save/epo_05-accu_0.4942.hdf5\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.5073 - val_loss: 0.6932 - val_accuracy: 0.4942 - lr: 7.2900e-04\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, epochs = EPOCH, verbose = 1,\n",
    "            validation_data = (x_test, y_test), callbacks = CallBack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-830ac7baefeaea3e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-830ac7baefeaea3e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir N_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRpsCx3NEAtx"
   },
   "source": [
    "<br>\n",
    "<b>Model-2</b>\n",
    "<pre>\n",
    "1. Use relu as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use RandomUniform(0,1) as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "btKuy2SWEFZo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 32)                96        \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense4 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense5 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,409\n",
      "Trainable params: 5,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_init = RandomUniform(0, 1)\n",
    "\n",
    "model = create_model('relu', kernel_init)\n",
    "\n",
    "optimizer_ = optimizers.SGD(learning_rate = 0.001, momentum = 0.9, name = 'SGD')\n",
    "\n",
    "model.compile(optimizer = optimizer_, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "\n",
    "log_dir = 'N_logs/2_relu_Random'\n",
    "tensorboard_ = TensorBoard(log_dir = log_dir, histogram_freq = 1, write_graph = True)\n",
    "\n",
    "CallBack_list = [roc_score, f1_score_, terminateNaN, early_stopping, model_check_point,\n",
    "                                                                     epoch_1, epoch_3, tensorboard_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/438 [..............................] - ETA: 2:46 - loss: 174661.0469 - accuracy: 0.5312WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.\n",
      "432/438 [============================>.] - ETA: 0s - loss: 1213.5258 - accuracy: 0.4941 ROC_test:0.5\n",
      " MicroF1_Test:0.494\n",
      "\n",
      "Epoch 1: saving model to me_model_save/epo_01-accu_0.4942.hdf5\n",
      "438/438 [==============================] - 3s 7ms/step - loss: 1198.2787 - accuracy: 0.4941 - val_loss: 0.6932 - val_accuracy: 0.4942 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "421/438 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5029 ROC_test:0.5\n",
      " MicroF1_Test:0.494\n",
      "\n",
      "Epoch 2: saving model to me_model_save/epo_02-accu_0.4942.hdf5\n",
      "\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4942 - lr: 9.0000e-04\n",
      "Epoch 3/20\n",
      "430/438 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5008 ROC_test:0.5\n",
      " MicroF1_Test:0.494\n",
      "\n",
      "Epoch 3: saving model to me_model_save/epo_03-accu_0.4942.hdf5\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4942 - lr: 8.1000e-04\n",
      "Epoch 3: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, epochs = EPOCH, verbose = 1,\n",
    "            validation_data = (x_test, y_test), callbacks = CallBack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3916), started 0:00:09 ago. (Use '!kill 3916' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cf36c0c80f7666c5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cf36c0c80f7666c5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir N_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1e2VaqfEEDE"
   },
   "source": [
    "<br>\n",
    "<b>Model-3</b>\n",
    "<pre>\n",
    "1. Use relu as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use he_uniform() as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "N2M4q3LYEF_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 32)                96        \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense4 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense5 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,409\n",
      "Trainable params: 5,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_init = HeUniform()\n",
    "\n",
    "model = create_model('relu', kernel_init)\n",
    "\n",
    "optimizer_ = optimizers.SGD(learning_rate = 0.001, momentum = 0.9, name = 'SGD')\n",
    "\n",
    "model.compile(optimizer = optimizer_, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "\n",
    "log_dir = 'N_logs/3_relu_HeUniform'\n",
    "tensorboard_ = TensorBoard(log_dir = log_dir, histogram_freq = 1, write_graph = True)\n",
    "\n",
    "CallBack_list = [roc_score, f1_score_, terminateNaN, early_stopping, model_check_point,\n",
    "                                                                     epoch_1, epoch_3, tensorboard_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WOaQiRbZEGDU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/438 [..............................] - ETA: 3:18 - loss: 0.9620 - accuracy: 0.5312WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "415/438 [===========================>..] - ETA: 0s - loss: 0.6914 - accuracy: 0.5336 ROC_test:0.705\n",
      " MicroF1_Test:0.574\n",
      "\n",
      "Epoch 1: saving model to me_model_save/epo_01-accu_0.5740.hdf5\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6904 - accuracy: 0.5369 - val_loss: 0.6698 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.6280 ROC_test:0.721\n",
      " MicroF1_Test:0.66\n",
      "\n",
      "Epoch 2: saving model to me_model_save/epo_02-accu_0.6602.hdf5\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6576 - accuracy: 0.6280 - val_loss: 0.6470 - val_accuracy: 0.6602 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "417/438 [===========================>..] - ETA: 0s - loss: 0.6328 - accuracy: 0.6586 ROC_test:0.72\n",
      " MicroF1_Test:0.646\n",
      "\n",
      "Epoch 3: saving model to me_model_save/epo_03-accu_0.6462.hdf5\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6322 - accuracy: 0.6585 - val_loss: 0.6305 - val_accuracy: 0.6462 - lr: 9.0000e-04\n",
      "Epoch 4/20\n",
      "411/438 [===========================>..] - ETA: 0s - loss: 0.6162 - accuracy: 0.6635 ROC_test:0.73\n",
      " MicroF1_Test:0.663\n",
      "\n",
      "Epoch 4: saving model to me_model_save/epo_04-accu_0.6627.hdf5\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6155 - accuracy: 0.6627 - val_loss: 0.6132 - val_accuracy: 0.6627 - lr: 9.0000e-04\n",
      "Epoch 5/20\n",
      "433/438 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.6677 ROC_test:0.729\n",
      " MicroF1_Test:0.659\n",
      "\n",
      "Epoch 5: saving model to me_model_save/epo_05-accu_0.6587.hdf5\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6071 - accuracy: 0.6674 - val_loss: 0.6135 - val_accuracy: 0.6587 - lr: 8.1000e-04\n",
      "Epoch 6/20\n",
      "431/438 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.6724 ROC_test:0.732\n",
      " MicroF1_Test:0.667\n",
      "\n",
      "Epoch 6: saving model to me_model_save/epo_06-accu_0.6668.hdf5\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6031 - accuracy: 0.6719 - val_loss: 0.6054 - val_accuracy: 0.6668 - lr: 8.1000e-04\n",
      "Epoch 7/20\n",
      "433/438 [============================>.] - ETA: 0s - loss: 0.6035 - accuracy: 0.6693 ROC_test:0.73\n",
      " MicroF1_Test:0.664\n",
      "\n",
      "Epoch 7: saving model to me_model_save/epo_07-accu_0.6643.hdf5\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6027 - accuracy: 0.6704 - val_loss: 0.6085 - val_accuracy: 0.6643 - lr: 7.2900e-04\n",
      "Epoch 8/20\n",
      "432/438 [============================>.] - ETA: 0s - loss: 0.6011 - accuracy: 0.6716 ROC_test:0.727\n",
      " MicroF1_Test:0.661\n",
      "\n",
      "Epoch 8: saving model to me_model_save/epo_08-accu_0.6612.hdf5\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6010 - accuracy: 0.6721 - val_loss: 0.6111 - val_accuracy: 0.6612 - lr: 6.5610e-04\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, epochs = EPOCH, verbose = 1,\n",
    "            validation_data = (x_test, y_test), callbacks = CallBack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3916), started 0:00:29 ago. (Use '!kill 3916' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-55405be2eb7849c5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-55405be2eb7849c5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir N_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w41Y3TFENCXk"
   },
   "source": [
    "<br>\n",
    "<b>Model-4</b>\n",
    "<pre>\n",
    "1. Try with any values to get better accuracy/f1 score.  \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4agdXzB-DqOj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 32)                96        \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense4 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " dense5 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,409\n",
      "Trainable params: 5,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_init = GlorotNormal()\n",
    "\n",
    "model = create_model('relu', kernel_init)\n",
    "\n",
    "optimizer_ = optimizers.SGD(learning_rate = 0.001, momentum = 0.9, name = 'SGD')\n",
    "\n",
    "model.compile(optimizer = optimizer_, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "\n",
    "log_dir = 'N_logs/4_relu_GlorotNormal'\n",
    "tensorboard_ = TensorBoard(log_dir = log_dir, histogram_freq = 1, write_graph = True)\n",
    "\n",
    "CallBack_list = [roc_score, f1_score_, terminateNaN, early_stopping, model_check_point,\n",
    "                                                                     epoch_1, epoch_3, tensorboard_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/438 [..............................] - ETA: 2:38 - loss: 0.6879 - accuracy: 0.6875WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.\n",
      "424/438 [============================>.] - ETA: 0s - loss: 0.6912 - accuracy: 0.5394 ROC_test:0.619\n",
      " MicroF1_Test:0.579\n",
      "\n",
      "Epoch 1: saving model to me_model_save/epo_01-accu_0.5787.hdf5\n",
      "438/438 [==============================] - 3s 5ms/step - loss: 0.6912 - accuracy: 0.5402 - val_loss: 0.6889 - val_accuracy: 0.5787 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "428/438 [============================>.] - ETA: 0s - loss: 0.6864 - accuracy: 0.5845 ROC_test:0.652\n",
      " MicroF1_Test:0.607\n",
      "\n",
      "Epoch 2: saving model to me_model_save/epo_02-accu_0.6072.hdf5\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6864 - accuracy: 0.5843 - val_loss: 0.6830 - val_accuracy: 0.6072 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "415/438 [===========================>..] - ETA: 0s - loss: 0.6805 - accuracy: 0.6052 ROC_test:0.669\n",
      " MicroF1_Test:0.617\n",
      "\n",
      "Epoch 3: saving model to me_model_save/epo_03-accu_0.6173.hdf5\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6802 - accuracy: 0.6048 - val_loss: 0.6754 - val_accuracy: 0.6173 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "411/438 [===========================>..] - ETA: 0s - loss: 0.6705 - accuracy: 0.6243 ROC_test:0.698\n",
      " MicroF1_Test:0.646\n",
      "\n",
      "Epoch 4: saving model to me_model_save/epo_04-accu_0.6457.hdf5\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6701 - accuracy: 0.6239 - val_loss: 0.6622 - val_accuracy: 0.6457 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "429/438 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.6560 ROC_test:0.728\n",
      " MicroF1_Test:0.666\n",
      "\n",
      "Epoch 5: saving model to me_model_save/epo_05-accu_0.6665.hdf5\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6528 - accuracy: 0.6561 - val_loss: 0.6417 - val_accuracy: 0.6665 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "409/438 [===========================>..] - ETA: 0s - loss: 0.6286 - accuracy: 0.6696 ROC_test:0.73\n",
      " MicroF1_Test:0.663\n",
      "\n",
      "Epoch 6: saving model to me_model_save/epo_06-accu_0.6630.hdf5\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6282 - accuracy: 0.6695 - val_loss: 0.6210 - val_accuracy: 0.6630 - lr: 9.0000e-04\n",
      "Epoch 7/20\n",
      "427/438 [============================>.] - ETA: 0s - loss: 0.6101 - accuracy: 0.6749 ROC_test:0.73\n",
      " MicroF1_Test:0.667\n",
      "\n",
      "Epoch 7: saving model to me_model_save/epo_07-accu_0.6667.hdf5\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6106 - accuracy: 0.6744 - val_loss: 0.6107 - val_accuracy: 0.6667 - lr: 9.0000e-04\n",
      "Epoch 8/20\n",
      "426/438 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.6732 ROC_test:0.732\n",
      " MicroF1_Test:0.668\n",
      "\n",
      "Epoch 8: saving model to me_model_save/epo_08-accu_0.6682.hdf5\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6036 - accuracy: 0.6735 - val_loss: 0.6076 - val_accuracy: 0.6682 - lr: 9.0000e-04\n",
      "Epoch 9/20\n",
      "429/438 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.6739 ROC_test:0.732\n",
      " MicroF1_Test:0.665\n",
      "\n",
      "Epoch 9: saving model to me_model_save/epo_09-accu_0.6653.hdf5\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6013 - accuracy: 0.6746 - val_loss: 0.6070 - val_accuracy: 0.6653 - lr: 8.1000e-04\n",
      "Epoch 10/20\n",
      "429/438 [============================>.] - ETA: 0s - loss: 0.6011 - accuracy: 0.6696 ROC_test:0.733\n",
      " MicroF1_Test:0.667\n",
      "\n",
      "Epoch 10: saving model to me_model_save/epo_10-accu_0.6670.hdf5\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6009 - accuracy: 0.6701 - val_loss: 0.6059 - val_accuracy: 0.6670 - lr: 7.2900e-04\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, epochs = EPOCH, verbose = 1,\n",
    "            validation_data = (x_test, y_test), callbacks = CallBack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3916), started 0:00:54 ago. (Use '!kill 3916' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bb40ade95cf65e09\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bb40ade95cf65e09\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir N_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP3-7U_4LhC6"
   },
   "source": [
    "# Note \n",
    "Make sure that you are plotting tensorboard plots either in your notebook or you can try to create a pdf file with all the tensorboard screenshots.Please write your analysis of tensorboard results for each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Comparision</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VPci2vqWMN2I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+--------------------+-------------------+--------+----------+----------+\n",
      "| Model | Activation Function | Kernal Initializer | No. of Epochs ran |  Loss  | Accuracy | ROC Test |\n",
      "+-------+---------------------+--------------------+-------------------+--------+----------+----------+\n",
      "|   1   |         tanh        |   RandomUniform    |         5         | 0.6933 |  0.5081  |  0.504   |\n",
      "|   2   |         relu        |   RandomUniform    |         3         | 0.6932 |  0.5006  |   0.5    |\n",
      "|   3   |         relu        |     HeUniform      |         8         | 0.6011 |  0.6776  |  0.727   |\n",
      "|   4   |         relu        |    GlarotNormal    |         10        | 0.6011 |  0.6701  |   0.73   |\n",
      "+-------+---------------------+--------------------+-------------------+--------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = ['Model', 'Activation Function', 'Kernal Initializer', 'No. of Epochs ran', 'Loss', 'Accuracy', 'ROC Test']\n",
    "x.add_row([1, 'tanh', 'RandomUniform', 5, 0.6933, 0.5081, 0.504])\n",
    "x.add_row([2, 'relu', 'RandomUniform', 3, 0.6932, 0.5006, 0.5])\n",
    "x.add_row([3, 'relu', 'HeUniform', 8, 0.6011, 0.6776, 0.727])\n",
    "x.add_row([4, 'relu', 'GlarotNormal', 10, 0.6011, 0.6701, 0.73])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Observation</font>**\n",
    "\n",
    "- This shows with activation function as `relu` and kernal initializer as `GlarotNormal` gives better **ROC Test** value than anu other models.\n",
    "- Also this models runs for 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'red'>TensorBoard Outpots</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'>Scalar</font>\n",
    "<img src = 'Scalars.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'>Graphs</font>\n",
    "<img src = 'https://i.imgur.com/BPlmgoE.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'>Distributions</font>\n",
    "<img src = 'https://i.imgur.com/4dpHQf0.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'>Histograms</font>\n",
    "<img src = 'https://i.imgur.com/WIWwXsr.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'blue'>Time Series</font>\n",
    "<img src = 'https://i.imgur.com/tO52xw1.jpg'>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Call_Backs_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
